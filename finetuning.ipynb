{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install","metadata":{}},{"cell_type":"code","source":"%%capture --no-stderr\n%pip install -q datasets==2.21.0 requests torch peft bitsandbytes transformers==4.43.1 trl accelerate sentencepiece tiktoken matplotlib wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:23:54.319710Z","iopub.execute_input":"2024-11-13T12:23:54.320171Z","iopub.status.idle":"2024-11-13T12:24:26.899626Z","shell.execute_reply.started":"2024-11-13T12:23:54.320138Z","shell.execute_reply":"2024-11-13T12:24:26.898401Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Import and Constants","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport math\nfrom tqdm import tqdm\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nfrom huggingface_hub import login\nimport torch\nimport transformers\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, set_seed, BitsAndBytesConfig\nfrom datasets import load_dataset, Dataset, DatasetDict\nimport wandb\nfrom peft import LoraConfig\nfrom trl import SFTTrainer, SFTConfig\nfrom datetime import datetime\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:24:26.901613Z","iopub.execute_input":"2024-11-13T12:24:26.901944Z","iopub.status.idle":"2024-11-13T12:24:49.014216Z","shell.execute_reply.started":"2024-11-13T12:24:26.901908Z","shell.execute_reply":"2024-11-13T12:24:49.013243Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Constants\n\nBASE_MODEL = \"meta-llama/Llama-3.2-1B\"\nPROJECT_NAME = \"estimator\"\nHF_USER = \"xonic48\"\n\n# Data\n\nDATASET_NAME = f\"{HF_USER}/pricer-data\"\n\nMAX_SEQUENCE_LENGTH = 182\n\n# Run name for saving the model in the hub\n\nRUN_NAME =  f\"{datetime.now():%Y-%m-%d_%H.%M.%S}\"\nPROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\nHUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\"\n\n# Hyperparameters for QLoRA\n\nLORA_R = 8\nLORA_ALPHA = 16\nTARGET_MODULES = [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\nLORA_DROPOUT = 0.1\nQUANT_4_BIT = True\n\n# Hyperparameters for Training\n\nEPOCHS = 1\nBATCH_SIZE = 16\nGRADIENT_ACCUMULATION_STEPS = 1\nLEARNING_RATE = 1e-4\nLR_SCHEDULER_TYPE = 'cosine'\nWARMUP_RATIO = 0.03\nOPTIMIZER = \"paged_adamw_32bit\"\n\n# Admin config\n\nSTEPS = 50\nSAVE_STEPS = 5000\nLOG_TO_WANDB = True\n\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:24:49.015675Z","iopub.execute_input":"2024-11-13T12:24:49.016265Z","iopub.status.idle":"2024-11-13T12:24:49.025874Z","shell.execute_reply.started":"2024-11-13T12:24:49.016230Z","shell.execute_reply":"2024-11-13T12:24:49.024984Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"HUB_MODEL_NAME","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:24:49.028558Z","iopub.execute_input":"2024-11-13T12:24:49.029234Z","iopub.status.idle":"2024-11-13T12:24:49.042044Z","shell.execute_reply.started":"2024-11-13T12:24:49.029168Z","shell.execute_reply":"2024-11-13T12:24:49.041102Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'xonic48/estimator-2024-11-13_12.24.49'"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## Login","metadata":{}},{"cell_type":"code","source":"# Log in to HuggingFace\n\nhf_token = user_secrets.get_secret('HF_TOKEN')\nlogin(hf_token, add_to_git_credential=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:24:49.043108Z","iopub.execute_input":"2024-11-13T12:24:49.043471Z","iopub.status.idle":"2024-11-13T12:24:49.977471Z","shell.execute_reply.started":"2024-11-13T12:24:49.043426Z","shell.execute_reply":"2024-11-13T12:24:49.976577Z"}},"outputs":[{"name":"stdout","text":"Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Log in to Weights & Biases\nwandb_api_key = user_secrets.get_secret('wandb')\nos.environ[\"WANDB_API_KEY\"] = wandb_api_key\nwandb.login()\n\n# Configure Weights & Biases to record against our project\nos.environ[\"WANDB_PROJECT\"] = PROJECT_NAME\nos.environ[\"WANDB_LOG_MODEL\"] = \"true\" if LOG_TO_WANDB else \"false\"\nos.environ[\"WANDB_WATCH\"] = \"gradients\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:24:49.978559Z","iopub.execute_input":"2024-11-13T12:24:49.978834Z","iopub.status.idle":"2024-11-13T12:24:51.933119Z","shell.execute_reply.started":"2024-11-13T12:24:49.978804Z","shell.execute_reply":"2024-11-13T12:24:51.932292Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgeneralarbs\u001b[0m (\u001b[33mgeneralarbs-jisce\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"if LOG_TO_WANDB:\n  wandb.init(project=PROJECT_NAME, name=RUN_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:24:51.934372Z","iopub.execute_input":"2024-11-13T12:24:51.934988Z","iopub.status.idle":"2024-11-13T12:24:55.312315Z","shell.execute_reply.started":"2024-11-13T12:24:51.934954Z","shell.execute_reply":"2024-11-13T12:24:55.311546Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113625622222243, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b28697ba93f246c78de43076e0806b33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241113_122451-yuqy3pt0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/generalarbs-jisce/estimator/runs/yuqy3pt0' target=\"_blank\">2024-11-13_12.24.49</a></strong> to <a href='https://wandb.ai/generalarbs-jisce/estimator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/generalarbs-jisce/estimator' target=\"_blank\">https://wandb.ai/generalarbs-jisce/estimator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/generalarbs-jisce/estimator/runs/yuqy3pt0' target=\"_blank\">https://wandb.ai/generalarbs-jisce/estimator/runs/yuqy3pt0</a>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(DATASET_NAME)\ntrain = dataset['train']\ntrain = dataset['train'].shuffle(seed=42).select(range(50000))\ntest = dataset['test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:24:55.313446Z","iopub.execute_input":"2024-11-13T12:24:55.313742Z","iopub.status.idle":"2024-11-13T12:25:08.758416Z","shell.execute_reply.started":"2024-11-13T12:24:55.313710Z","shell.execute_reply":"2024-11-13T12:25:08.757439Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/416 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6225ac42c8404b6581cef42c7cecb6cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/187M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"392e503b4b9742f090b9d5a1b14e42d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/922k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"869477fcc4c44cb3b3a5896e63dad760"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/400000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc2ce1b56baa486a9e5f7139b8df2f55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b266c1d7487747979a47ea91667b3d15"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:25:08.759673Z","iopub.execute_input":"2024-11-13T12:25:08.760395Z","iopub.status.idle":"2024-11-13T12:25:08.767241Z","shell.execute_reply.started":"2024-11-13T12:25:08.760350Z","shell.execute_reply":"2024-11-13T12:25:08.766354Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'price'],\n    num_rows: 50000\n})"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Load the Tokenizer and 4-bit Model","metadata":{}},{"cell_type":"code","source":"# pick the right quantization\n\nif QUANT_4_BIT:\n  quant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_quant_type=\"nf4\"\n  )\nelse:\n  quant_config = BitsAndBytesConfig(\n    load_in_8bit=True,\n    bnb_8bit_compute_dtype=torch.bfloat16\n  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:25:08.771661Z","iopub.execute_input":"2024-11-13T12:25:08.771995Z","iopub.status.idle":"2024-11-13T12:25:09.459245Z","shell.execute_reply.started":"2024-11-13T12:25:08.771960Z","shell.execute_reply":"2024-11-13T12:25:09.458243Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Load the Tokenizer and the Model\n\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    quantization_config=quant_config,\n    device_map=\"auto\",\n)\nbase_model.generation_config.pad_token_id = tokenizer.pad_token_id\n\nprint(f\"Memory footprint: {base_model.get_memory_footprint() / 1e6:.1f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:25:09.461254Z","iopub.execute_input":"2024-11-13T12:25:09.461906Z","iopub.status.idle":"2024-11-13T12:26:16.269749Z","shell.execute_reply.started":"2024-11-13T12:25:09.461858Z","shell.execute_reply":"2024-11-13T12:26:16.268664Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a615328e87ce47c594bc6130222efa5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dec66f6582f443259eee462bfb0b2cf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"852815f070b243ef9aee2a4d9592283c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1199e26560a485ca532c44f8a399be5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e07415365b7c4acabcf17e3ac1a0f8c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22c29d723f97424eab7f9bfcdfdfb627"}},"metadata":{}},{"name":"stdout","text":"Memory footprint: 1012.0 MB\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Data Collator\r\n\r\nIt's important that we ensure during Training that we are not trying to train the model to predict the description of products; only their price.\r\n\r\nWe need to tell the trainer that everything up to \"Price is $\" is there to give context to the model to predict the next token, but does not need to be learned.\r\n\r\nThe trainer needs to teach the model to predict the token(s) after \"Price is $\".\r\n\r\nThere is a complicated way to do this by setting Masks, but luckily HuggingFace provides a super simple helper class to take care of this for us.","metadata":{}},{"cell_type":"code","source":"from trl import DataCollatorForCompletionOnlyLM\nresponse_template = \"Price is $\"\ncollator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:26:16.270982Z","iopub.execute_input":"2024-11-13T12:26:16.271338Z","iopub.status.idle":"2024-11-13T12:26:16.277224Z","shell.execute_reply.started":"2024-11-13T12:26:16.271304Z","shell.execute_reply":"2024-11-13T12:26:16.276331Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Training Config (LORAConfig, SFTTrainer and SFTConfig)","metadata":{}},{"cell_type":"code","source":"# First, specify the configuration parameters for LoRA\n\nlora_parameters = LoraConfig(\n    lora_alpha=LORA_ALPHA,\n    lora_dropout=LORA_DROPOUT,\n    r=LORA_R,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=TARGET_MODULES,\n)\n\n# Next, specify the general configuration parameters for training\n\ntrain_parameters = SFTConfig(\n    output_dir=PROJECT_RUN_NAME,\n    num_train_epochs=EPOCHS,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=1,\n    eval_strategy=\"no\",\n    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n    optim=OPTIMIZER,\n    save_steps=SAVE_STEPS,\n    save_total_limit=10,\n    logging_steps=STEPS,\n    learning_rate=LEARNING_RATE,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=True,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=WARMUP_RATIO,\n    group_by_length=True,\n    lr_scheduler_type=LR_SCHEDULER_TYPE,\n    report_to=\"wandb\" if LOG_TO_WANDB else None,\n    run_name=RUN_NAME,\n    max_seq_length=MAX_SEQUENCE_LENGTH,\n    dataset_text_field=\"text\",\n    save_strategy=\"steps\",\n    hub_strategy=\"every_save\",\n    push_to_hub=True,\n    hub_model_id=HUB_MODEL_NAME,\n    hub_private_repo=True\n)\n\n# And now, the Supervised Fine Tuning Trainer will carry out the fine-tuning\n# Given these 2 sets of configuration parameters\n\nfine_tuning = SFTTrainer(\n    model=base_model,\n    train_dataset=train,\n    peft_config=lora_parameters,\n    tokenizer=tokenizer,\n    args=train_parameters,\n    data_collator=collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:26:16.278463Z","iopub.execute_input":"2024-11-13T12:26:16.279127Z","iopub.status.idle":"2024-11-13T12:26:30.883790Z","shell.execute_reply.started":"2024-11-13T12:26:16.279078Z","shell.execute_reply":"2024-11-13T12:26:30.882790Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9753300949e4d368760ef29cea262e7"}},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## Finetune or Training","metadata":{}},{"cell_type":"code","source":"# Fine-tune!\nfine_tuning.train()\n\n# Push our fine-tuned model to Hugging Face\nfine_tuning.model.push_to_hub(PROJECT_RUN_NAME, private=True)\nprint(f\"Saved to the hub: {PROJECT_RUN_NAME}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T12:26:30.885080Z","iopub.execute_input":"2024-11-13T12:26:30.885467Z","iopub.status.idle":"2024-11-13T18:34:14.269838Z","shell.execute_reply.started":"2024-11-13T12:26:30.885425Z","shell.execute_reply":"2024-11-13T18:34:14.268750Z"}},"outputs":[{"name":"stderr","text":"We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3125/3125 6:07:19, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>2.507000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.977600</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.958200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.957800</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.930400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.938200</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.948200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.900300</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.931500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.930300</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.907800</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.908700</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.938000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.910800</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.894000</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.925400</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.897800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.925600</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.909600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.879300</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.912500</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.886600</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>1.885300</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.876000</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>1.867200</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.860000</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>1.883600</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.891100</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>1.889000</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.893500</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>1.897500</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.900000</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>1.906100</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>1.872800</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>1.899900</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>1.910300</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>1.895700</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1.873800</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>1.849200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.884700</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>1.864800</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>1.878600</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>1.886400</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>1.870500</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>1.848300</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>1.901000</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>1.855100</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>1.864400</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>1.865400</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.866300</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>1.864600</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>1.858200</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>1.890700</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>1.891900</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>1.896900</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>1.856900</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>1.878400</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>1.877500</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>1.888700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.894300</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>1.861400</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>1.867100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8b913a3b8344c06a0a1b8f2b7694c99"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Saved to the hub: estimator-2024-11-13_12.24.49\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"if LOG_TO_WANDB:\n  wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:34:14.271099Z","iopub.execute_input":"2024-11-13T18:34:14.271642Z","iopub.status.idle":"2024-11-13T18:34:20.239421Z","shell.execute_reply.started":"2024-11-13T18:34:14.271608Z","shell.execute_reply":"2024-11-13T18:34:20.238648Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='4.163 MB of 15.547 MB uploaded\\r'), FloatProgress(value=0.26778858463100835, max=1…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d27db0ab88f4bb7937fc87c657ab43a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▆█▃▂▄▆▆▂▂▁▄▃▂▃▆▄▃▃▃▂▂▃▂▂▃▃▂▅▄▂▃▄▄▃▃▂▄▄▂▅</td></tr><tr><td>train/learning_rate</td><td>██████████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▂▂▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>5.19926992528343e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>3125</td></tr><tr><td>train/grad_norm</td><td>2.46936</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.8671</td></tr><tr><td>train_loss</td><td>1.90351</td></tr><tr><td>train_runtime</td><td>22037.8033</td></tr><tr><td>train_samples_per_second</td><td>2.269</td></tr><tr><td>train_steps_per_second</td><td>0.142</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">2024-11-13_12.24.49</strong> at: <a href='https://wandb.ai/generalarbs-jisce/estimator/runs/yuqy3pt0' target=\"_blank\">https://wandb.ai/generalarbs-jisce/estimator/runs/yuqy3pt0</a><br/> View project at: <a href='https://wandb.ai/generalarbs-jisce/estimator' target=\"_blank\">https://wandb.ai/generalarbs-jisce/estimator</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241113_122451-yuqy3pt0/logs</code>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(base_model, PROJECT_RUN_NAME)\n\n# Merge the LoRA weights with the base model\npeft_model = peft_model.merge_and_unload()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:34:20.240453Z","iopub.execute_input":"2024-11-13T18:34:20.240790Z","iopub.status.idle":"2024-11-13T18:34:20.515532Z","shell.execute_reply.started":"2024-11-13T18:34:20.240754Z","shell.execute_reply":"2024-11-13T18:34:20.500913Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m peft_model \u001b[38;5;241m=\u001b[39m \u001b[43mPeftModel\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(base_model, PROJECT_RUN_NAME)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Merge the LoRA weights with the base model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m peft_model \u001b[38;5;241m=\u001b[39m peft_model\u001b[38;5;241m.\u001b[39mmerge_and_unload()\n","\u001b[0;31mNameError\u001b[0m: name 'PeftModel' is not defined"],"ename":"NameError","evalue":"name 'PeftModel' is not defined","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"peft_model.save_pretrained(f\"{PROJECT_RUN_NAME}_day1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T18:34:20.516412Z","iopub.status.idle":"2024-11-13T18:34:20.516768Z","shell.execute_reply.started":"2024-11-13T18:34:20.516596Z","shell.execute_reply":"2024-11-13T18:34:20.516614Z"}},"outputs":[],"execution_count":null}]}